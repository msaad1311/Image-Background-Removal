{"version":3,"sources":["index.js"],"names":["document","getElementById","onload","onLoad","console","log","MODEL_URL","WEIGHTS_URL","TENSOR_EDGE","tf","loadGraphModel","model"],"mappings":";;;;AAAAA,QAAQ,CAACC,cAAT,CAAwB,UAAxB,EAAoCC,MAApC,GAA6C,YAAW;AAACC,EAAAA,MAAM;AAAG,CAAlE;;SAGeA;;EAiBf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;oEAjDA;AAAA;AAAA;AAAA;AAAA;AAAA;AACIC,YAAAA,OAAO,CAACC,GAAR,CAAY,eAAZ;AACIC,YAAAA,SAFR,GAEoB,mCAFpB;AAGQC,YAAAA,WAHR,GAGsB,mCAHtB,EAIE;;AACMC,YAAAA,WALR,GAKsB,GALtB;AAAA;AAAA,mBAMsBC,EAAE,CAACC,cAAH,CAAkBH,WAAlB,CANtB;;AAAA;AAMQI,YAAAA,KANR;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA","file":"Application.e31bb0bc.js","sourceRoot":"..","sourcesContent":["document.getElementById('mainBody').onload = function() {onLoad()}\r\n\r\n\r\nasync function onLoad() {\r\n    console.log('onLoad loaded')\r\n  const MODEL_URL = \"preTrained\\\\tensorflowjs_model.pb\";\r\n  const WEIGHTS_URL = \"preTrained\\\\weights_manifest.json\";\r\n  // Model's input and output have width and height of 513.\r\n  const TENSOR_EDGE = 513;\r\n  const model = await tf.loadGraphModel(WEIGHTS_URL);\r\n  // const model = await tf.loadFrozenModel(MODEL_URL, WEIGHTS_URL)\r\n  // const [model, stream] =await Promise.all([\r\n  //   tf.loadFrozenModel(MODEL_URL, WEIGHTS_URL),\r\n  //   navigator.mediaDevices.getUserMedia({\r\n  //     video: { facingMode: \"user\", frameRate: 30, width: 640, height: 480 },\r\n  //   }),\r\n  // ]);\r\n}\r\n\r\n\r\n// const video = document.createElement(\"video\");\r\n// video.autoplay = true;\r\n// video.width = video.height = TENSOR_EDGE;\r\n// const ctx = document.getElementById(\"canvas\").getContext(\"2d\");\r\n// const videoCopy = ctx.canvas.cloneNode(false).getContext(\"2d\");\r\n// const maskContext = document.createElement(\"canvas\").getContext(\"2d\");\r\n// maskContext.canvas.width = maskContext.canvas.height = TENSOR_EDGE;\r\n// const img = maskContext.createImageData(TENSOR_EDGE, TENSOR_EDGE);\r\n// let imgd = img.data;\r\n// new Uint32Array(imgd.buffer).fill(0x00ffff00);\r\n// const render = () => {\r\n//   videoCopy.drawImage(video, 0, 0, ctx.canvas.width, ctx.canvas.height);\r\n//   const out = tf.tidy(() => {\r\n//     return model.execute({ ImageTensor: tf.fromPixels(video).expandDims(0) });\r\n//   });\r\n//   const data = out.dataSync();\r\n//   for (let i = 0; i < data.length; i++) {\r\n//     imgd[i * 4 + 3] = data[i] == 15 ? 0 : 255;\r\n//   }\r\n//   maskContext.putImageData(img, 0, 0);\r\n//   ctx.drawImage(videoCopy.canvas, 0, 0);\r\n//   if (document.getElementById(\"show-background-toggle\").checked)\r\n//     ctx.drawImage(\r\n//       maskContext.canvas,\r\n//       0,\r\n//       0,\r\n//       ctx.canvas.width,\r\n//       ctx.canvas.height\r\n//     );\r\n//   window.requestAnimationFrame(render);\r\n// };\r\n// video.oncanplay = render;\r\n// video.srcObject = stream;\r\n"]}